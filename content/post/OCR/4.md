---
title: "[OCR] UnrealText, SRNet"
date: 2022-04-12T00:00:00+09:00
categories:
- OCR
tags:
- Synthetic text image
thumbnailImage: /images/OCR/4-fig3.jpg
thumbnailImagePosition: right
summary: Synthetic text image (3) - 창의적인 방법
---
{{< alert info >}}
On Writting
{{< /alert >}}
앞서 다룬 인조 데이터들의 생성 방식은 어찌 보면 단순하다. OCR 인조 데이터가 필요하다면 MJ와 ST가 없더라도 아마 비슷한 방법으로 데이터를 생성했을 것이다. 이번엔 좀 더 창의적인 방법들을 소개해 보려 한다.

#### \#
[UnrealText](https://arxiv.org/abs/2003.10608)는 3D 그래픽 엔진(Unreal Engine 4.22)을 이용해 scene text image를 생성하는 법을 연구했다. ST와 비교했을 때 동일한 양의 학습 데이터로 더 높은 STD 모델 성능을 얻는데 성공했다. UnrealText 이전에 [SynthText3D](https://arxiv.org/abs/1907.06007)가 먼저 발행되었지만 어느 정도 퀄리티의 차이가 있다.

{{< image classes="center" src="/images/OCR/4-fig1.jpg" title="Fig. 1: Demonstration of the proposed UnrealText synthesis engine" >}}
{{< image classes="center" src="/images/OCR/4-fig2.png" title="Fig. 2: Detection results (F-1 score)" >}}

Fig.1의 예시 이미지를 보면 그림자, 자연스러운 위치, 장애물 등 ST에서는 얻을 수 없는 결과들을 확인할 수 있다. 광원, 오브젝트 그리고 텍스처 등이 한데 어우러져 인조 데이터 생성에 대한 새로운 가능성을 제시했다. 문제는 필자가 직접 UnrealText 데이터를 학습해 본 결과가 별로 좋지 못했다. 일단 예시의 이미지처럼 데이터 전체가 훌륭하진 않았다. 대부분의 경우 이질감이 심하고 부자연스러웠다. 또 그래픽 엔진의 한계인지 배경이 너무 단조로웠다. 이미지 수 자체가 적지는 않았지만 다채롭다는 느낌을 전혀 받을 수 없었다. 그 밖의 여러 점들이 합쳐져 좋은 결과로 이어지지 못한 것 같다.  
UnrealText의 데이터 자체는 아쉬운 부분이 많지만 논문에서 주목한 부분들은 상당히 의미있다고 본다. 

#### \#
[SRNet(Style Retention Network)](https://arxiv.org/abs/1908.03047)은 OCR 인조 데이터 생성을 위해 연구된 모델은 아니다. 이미지 번역 등에서 사용하기 위해 만들어진 이미지 합성 모델이다. 하지만 GAN을 기본 구조로 사용했기에 이 모델의 기본 목표는 자연스러움이다. 

{{< image classes="center" src="/images/OCR/4-fig3.jpg" title="Fig. 3: Sample images of SRNet" >}}
{{< image classes="center" src="/images/OCR/4-fig4.png" title="Fig. 4:  The overall structure of SRNet" >}}

Fig.4에서 모델의 전체 구조가 단순하지만 어려 개의 모듈로 나뉘어 있음을 파악할 수 있다.  
1\. 원본 이미지에서 텍스트만을 지워주는 모듈  
2\. 입력 텍스트를 원본 이미지의 텍스트와 유사한 폰트로 바꿔주는 모듈  
3\. 그 둘을 자연스럽게 합성해주는 모듈  
모델의 구조를 보면 가장 큰 문제는 원본 이미지에서 교체할 텍스트의 영역을 직접 잡아줘야 한다는 것이다. 그나마 다행인 것은 텍스트의 내용까지 annotation할 필요가 없다는 거지만 인조 데이터를 만들기 위해 라벨링된 데이터가 필요하다는 사실은 달라지지 않는다. (애초부터 데이터 생성 위한 모델은 아니었다.)  


#### \#
Scene text image 합성을 위해 많은 연구들이 진행되었지만 아직까지는 부족한 부분이 많다. 논문이 목표한 바를 이해하고 예시 이미지를 보면 결과가 이상적으로 느껴지지만 전체 데이터를 보거나 해당 코드로 직접 데이터를 생성해 보면 예시 이미지와의 괴리가 상당하다. 데이터를 생성하다보면 확률적으로 이상적인 이미지가 생성되기도 하지만 대부분의 경우 어딘가 어색한 것이 아직까지의 현실이다.

#### Experience
```dockerfile
FROM nvcr.io/nvidia/pytorch:21.12-py3
```

#### Reference
[1] S. Long et al. [UnrealText: Synthesizing Realistic Scene Text Images from the Unreal World](https://arxiv.org/abs/2003.10608)  
[2] L. Wu et al. [Editing Text in the Wild](https://arxiv.org/abs/1908.03047)