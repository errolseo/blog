---
title: "[OCR] Synthetic Text Image (3)"
date: 2022-04-12T00:00:00+09:00
categories:
- OCR
tags:
- Synthetic Text Image
- UnrealText
- SRNet
thumbnailImage: /images/OCR/4-3.jpg
summary: UnrealText, SRNet
---
MJ와 ST의 데이터는 강력하지만 단조로운 면이 있다. MJ와 ST가 없더라도 OCR 인조 데이터가 필요하다면 아마 비슷한 방법의 시도가 이루어졌을 것이다. 이번엔 좀 더 창의적인 방법들을 소개해 보려 한다.

#### \#
[UnrealText](https://arxiv.org/abs/2003.10608)는 3D 그래픽 엔진(Unreal Engine 4.22)을 이용해 scene text image를 생성하는 법을 연구했다. ST와 비교했을 때 동일한 양의 학습 데이터로 더 높은 STD 모델 성능을 얻는데 성공했다. UnrealText 이전에 [SynthText3D](https://arxiv.org/abs/1907.06007)가 먼저 발행되었지만 어느 정도 퀄리티의 차이가 있다.

{{< image classes="center" src="/images/OCR/4-1.jpg" title="Figure 1. Demonstration of the proposed UnrealText synthesis engine" >}}
{{< image classes="center" src="/images/OCR/4-2.png" title="Figure 2. Detection results (F-1 score)" >}}

Fig.1의 예시 이미지를 보면 그림자, 자연스러운 위치, 장애물 등 ST에서는 얻을 수 없는 결과들을 확인할 수 있다. 광원, 오브젝트 그리고 텍스처 등이 한데 어우러져 인조 데이터 생성에 대한 새로운 가능성을 제시했다. 문제는 필자가 직접 UnrealText 데이터를 학습해 본 결과가 별로 좋지 못했다. 일단 예시의 이미지처럼 데이터 전체가 훌륭하진 않았다. 대부분의 경우 이질감이 심하고 부자연스러웠다. 또 그래픽 엔진의 한계인지 배경이 너무 단조로웠다. 이미지 수 자체가 적지는 않았지만 다채롭다는 느낌을 전혀 받을 수 없었다. 논문의 지표 상으로는 비슷한 양의 데이터를 학습했을 때 ST보다 좋은 성능을 보여준지만, 해당 샘플을 추출한 방법이 무작위인 것 같지는 않다.


UnrealText의 데이터 자체는 아쉬운 부분이 많지만 논문에서 주목한 부분들은 상당히 의미있다고 본다. 

#### \#
[SRNet(Style Retention Network)](https://arxiv.org/abs/1908.03047)은 OCR 인조 데이터 생성을 위해 연구된 모델은 아니다. 이미지 번역 등에서 사용하기 위해 만들어진 이미지 합성 모델이다. 하지만 GAN을 기본 구조로 사용했기에 이 모델의 기본 목표는 자연스러움이다. 

{{< image classes="center" src="/images/OCR/4-3.jpg" title="Figure 3. Sample images of SRNet" >}}
{{< image classes="center" src="/images/OCR/4-4.png" title="Figure 4. The overall structure of SRNet" >}}

모델의 전체 구조는 단순하지만 어려 개의 모듈로 나뉘어 있음을 Fig.4를 통해 파악할 수 있다.
1. 원본 이미지에서 텍스트만을 지워주는 모듈
2. 입력 텍스트를 원본 이미지의 텍스트와 유사한 폰트로 바꿔주는 모듈
3. 그 둘을 자연스럽게 합성해주는 모듈

모델의 구조를 보면 가장 큰 문제는 원본 이미지에서 교체할 텍스트의 영역을 직접 잡아줘야 한다는 것이다. 그나마 다행인 것은 텍스트의 내용까지는 필요가 없다는 거지만, 인조 데이터를 만들기 위해 annotation이 필요하다는 사실은 달라지지 않는다. (애초부터 데이터 생성 위한 모델은 아니었다.)

#### \#
Scene text image 합성을 위해 많은 연구들이 진행되었지만 아직까지는 부족한 부분이 많다. 논문이 목표한 바를 이해하고 예시 이미지를 보면 결과가 이상적으로 느껴지지만 전체 데이터를 보거나 해당 코드로 직접 데이터를 생성해 보면 예시 이미지와의 괴리가 상당하다. 데이터를 생성하다보면 확률적으로 이상적인 이미지가 생성되기도 하지만 대부분의 경우 어딘가 어색한 것이 아직까지의 현실이다. 

#### Reference
[1] S. Long et al. [UnrealText: Synthesizing Realistic Scene Text Images from the Unreal World](https://arxiv.org/abs/2003.10608)

[2] L. Wu et al. [Editing Text in the Wild](https://arxiv.org/abs/1908.03047)