---
title: "[OCR] Synthetic text image (3)"
date: 2022-04-12T00:00:00+09:00
categories:
- OCR
tags:
- unrealtext
- style retention network
thumbnailImage: 
thumbnailImagePosition: right
summary: unrealtext / style retention network (SRNet)
katex: true
---
{{< alert warning >}}
본문의 내용은 개인적인 정리를 위해 작성되었기에 학술적이지 않습니다.  
또한 증명되지 않은 내용이 포함되어 있을 가능성이 존재합니다.
{{< /alert >}}

### 1.
앞서 다룬 인조 데이터들의 생성 방식은 대부분 비슷하다. 

### 2.
[UnrealText](https://arxiv.org/abs/2003.10608)는 3D 그래픽 엔진(Unreal Engine 4.22)를 사용해 scene text image를 생성해냈다. 논문에서는 ST와 비교했을 때 동일한 양의 학습 이미지를 사용 더 높은 scene text detection(STD) 모델 성능을 
{{< image classes="center" src="/images/OCR/4-fig1.png" title="Fig. 1: Demonstration of the proposed UnrealText synthesis engine" >}}
{{< image classes="center" src="/images/OCR/4-fig2.png" title="Fig. 2: Illustration of the refinement of initial proposals" >}}



Scene text image 합성을 위해 많은 연구들이 진행되었지만 아직까지는 부족한 부분이 많다. 논문이 목표한 바를 이해하고 예시 이미지를 보면 결과가 이상적으로 느껴질 수 있다. 하지만 전체 데이터를 보거나 해당 코드로 직접 데이터를 생성해 보면 예시 이미지와의 괴리가 존재한다. 데이터를 생성하다보면 확률적으로 이상적인 이미지가 생성되기도 하지만 대부분의 경우 어딘가 어색한 것이 아직까지의 현실이다. 

#### Reference
[1] S. Long et al. [UnrealText: Synthesizing Realistic Scene Text Images from the Unreal World](https://arxiv.org/abs/2003.10608)