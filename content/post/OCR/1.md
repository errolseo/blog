---
title: Optical Text Recognition (OCR)
date: 2022-02-22
categories:
- OCR
thumbnailImage: /images/OCR/1/1.webp
summary: OCR에 대한 설명 (모델과 데이터를 기준으로)
---
광학 문자 인식(Optical Text Recognition, OCR)은 크게 두 가지 유형으로 나눌 수 있습니다. 하나는 <strong>{{<hl-text primary>}}정형화된 문서 이미지{{</hl-text>}}</strong>(그림 1)이고, 다른 하나는 <strong>{{<hl-text primary>}}비정형적인 자연 이미지{{</hl-text>}}</strong>(그림 2)입니다.

---
{{<image classes="center" src="/images/OCR/1/1.webp">}}
> 그림 1. Document OCR<br>
[© CLOVA OCR](https://www.ncloud.com/product/aiService/ocr#detail)

{{<image classes="center" src="/images/OCR/1/2.webp">}}
> 그림 2. Scene Text OCR<br>
[Youngmin Baek, et al. (2020)](https://arxiv.org/abs/2007.09629)

필자는 주로 Scene Text OCR에 대해 다루고 있습니다. Scene Text OCR은 {{<hl-text primary>}}불규칙한 텍스트 형태, 다양한 폰트, 크기, 색상, 복잡한 배경 등{{</hl-text>}} 다양한 변수들로 인해 Document OCR보다 인식 난이도가 훨씬 높습니다.

---
## Model
OCR은 크게 <strong>텍스트 검출(Detection)</strong>과 <strong>텍스트 인식(Recognition)</strong> 두 가지 주요 파트로 나뉩니다. 일반적으로 이 두 파트는 각각 독립적인 Detection 모델과 Recognition 모델로 구성됩니다.

{{<image classes="center" src="/images/OCR/1/3.webp">}}
> 그림 3. Text Detection<br>
[Youngmin Baek, et al. (2019)](https://arxiv.org/abs/1904.01941)

{{<image classes="center" src="/images/OCR/1/4.webp">}}
> 그림 4. Text Recognition<br>
[Jeonghun Baek, et al. (2019)](https://arxiv.org/abs/1904.01906)

검출 및 인식 모델을 {{<hl-text primary>}}분리하여 학습하는 주된 이유는 각 단계의 목적과 그에 따라 요구되는 입출력 형태가 다르기 때문{{</hl-text>}}입니다. <strong>Detection 모델</strong>은 전체 이미지를 입력받아 이미지 내 텍스트 영역(Wordbox)을 찾아내는 것을 목표로 하며, 이는 불필요한 배경 정보의 영향을 최소화시킵니다.

반면 <strong>Recognition 모델</strong>은 Detection 모델이 추출한 Wordbox를 입력받아 해당 영역 내의 문자를 실제 텍스트 문자열로 변환하는 것을 목표로 합니다. 이렇게 역할을 분리함으로써 각 모델은 자신에게 최적화된 데이터와 아키텍처로 학습될 수 있으며, 이는 전체 OCR 시스템의 정확성과 효율성을 높이게 됩니다.

---
## Data
최근 OCR 시스템 개발에서 <strong>합성 데이터(synthetic text image)</strong>의 활용은 선택이 아닌 필수가 되어가고 있습니다. 이는 고품질의 실제 OCR 학습 데이터를 수집하고 주석을 다는 과정이 막대한 시간과 비용을 필요로 하기 때문입니다. 반면 {{<hl-text primary>}}합성 데이터는 프로그램을 이용해 대량 생산이 가능{{</hl-text>}}해서 모델 학습에 필요한 충분한 양의 데이터를 빠르게 확보할 수 있다는 큰 장점을 있습니다.

또한 {{<hl-text primary>}}실제 데이터만으로는 다양한 글꼴, 크기, 색상, 배경, 조명, 왜곡, 노이즈, 각도 등 가능한 모든 시나리오를 포괄하는 것은 불가능{{</hl-text>}}에 가깝습니다. 특정 시나리오를 의도적으로 수집하기 어려울 뿐만 아니라, 특정 언어, 특수 문자, 필기체, 손상된 문서 등은 애초에 해당 데이터 자체가 부족한 경우도 많습니다. 이러한 문제들의 보완을 위해 합성 데이터를 활용하는 것은 모델의 성능을 향상시키는 동시에 비용 효율성도 높일 수 있습니다.

게다가 민감한 정보가 포함된 실제 문서를 사용할 때 발생할 수 있는 개인정보 보안 문제 역시 합성 데이터를 통해 효과적으로 해결할 수 있습니다.

{{<image classes="center" src="/images/OCR/1/5.webp">}}
> 그림 5. Synthetic text images<br>
[Ankush Gupta, et al. (2016)](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16/)

합성 데이터는 OCR 시스템 개발에 많은 이점을 제공하지만 한계점도 분명히 존재합니다. {{<hl-text primary>}}아무리 정교하게 만들어진 합성 데이터라 할지라도 현실을 완벽하게 반영하기는 어렵습니다.{{</hl-text>}} 현실에는 그림자나 광택처럼 예측 불가능한 다양한 노이즈가 존재하는데, 합성 데이터가 이러한 노이즈나 왜곡을 적절히 담아내지 못할 수 있습니다.

또한 합성 데이터의 사용은 <strong>과적합(Overfitting) 위험</strong>을 수반합니다. 합성 데이터가 실제 데이터의 분포를 충분히 반영하지 못할 경우, 모델이 합성 데이터의 특정 패턴에 과적합되어 실제 데이터에서의 성능이 저하될 수 있습니다. 특히 생성 방식이 단순하거나 다양성이 부족한 경우에 이러한 문제가 심화됩니다.

게다가 합성 데이터의 품질 평가가 어렵다는 점도 주요 한계로 지적됩니다. 생성된 합성 데이터가 현실을 얼마나 잘 반영하는지 정량적으로 평가하기 쉽지 않기 때문입니다. 단순히 시각적으로 유사한 데이터를 생성하는 것만으로는 모델 성능 향상으로 직결되지 않으므로, 실제 학습을 통해 모델 성능에 어떻게 기여하는지 파악하고 데이터 생성 전략을 수정할 필요가 있습니다.

---
#### Reference
[1] Baek, Jeonghun (2019) | [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis](https://arxiv.org/abs/1904.01906)

[2] Baek, Youngmin (2019) | [Character Region Awareness for Text Detection](https://arxiv.org/abs/1904.01941)

[3] Baek, Youngmin (2020) | [Character Region Attention For Text Spotting](https://arxiv.org/abs/2007.09629)

[4] Gupta, Ankush (2016) | [Synthetic Data for Text Localisation in Natural Images](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16)

[5] NAVER Cloud Platform | [CLOVA OCR](https://www.ncloud.com/product/aiService/ocr#detail)

---