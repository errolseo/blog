---
title: "[OCR] Optical Text Recognition"
date: 2022-02-22T00:00:00+09:00
categories:
- OCR
tags:
- Introduction
thumbnailImage: /images/OCR/1-2.png
summary: Introduction to OCR
---
{{< image classes="center" src="/images/OCR/1-1.jpg" title="Figure 1. Document OCR" >}}
{{< image classes="center" src="/images/OCR/1-2.png" title="Figure 2. Scene text OCR" >}}

Optical Text Recognition(OCR)은 크게 2 가지, {{< hl-text primary >}}<b>일정한 형식</b>이 존재하는 문서 등의 이미지{{< /hl-text >}}(Fig.1) 혹은 {{< hl-text primary >}}<b>다양한 형태</b>의 일반적인 이미지{{< /hl-text >}}(Fig.2)로 나눌 수 있다. 앞으로 필자가 정리할 내용은 후자에 해당하는 **scene text** 를 어떻게 탐지(Detection)하고 인식(Recognition)하는지에 대한 내용이다. 만약 본인이 하는 OCR 프로젝트가 document OCR에 가깝다면 다른 글을 찾아보길 추천한다.

Scene text OCR은 document OCR과 달리 포맷이 일정하지 않으며 이미지 속 텍스트의 존재가 보장되지 않는다. 또한 다양한 서체(Font)나 형태(Transform) 등의 이유로 성능을 높히는 것이 쉽지 않았다. 하지만 최근 많은 연구를 통해 그 성능이 점점 높아지고 있다.

#### \#
OCR은 detection과 recognition, 두 파트로 나누어져 있다. 기본적으로 두 파트는 Scene Text Detection(STD)과 Scene Text Recognition(STR)이란 **서로 독립된 모델**로 존재한다. 하지만 경우에 따라선 하나의 모델 안에 두 파트가 모두 존재할 수도 있다.

{{< image classes="center" src="/images/OCR/1-3.png" title="Figure 3. Scene text dectection" >}}
{{< image classes="center" src="/images/OCR/1-4.png" title="Figure 4. Scene text recognition" >}}

STD 모델은 scene text image를 입력으로 받아 word box image(Fig.3의 빨간 박스)를 출력하고, STR 모델은 word box image를 입력으로 받아 텍스트를 출력한다.(Fig.4) 이처럼 두 개의 모델로 나누어서 학습하는 이유는 단순하면서 복잡하다. 기본적으로 작업의 난이도를 대폭 낮출 수 있으나 배경 정보를 소실하는 문제가 있다. 더 자세하고 정확한 내용은 OCR에 대한 지식을 쌓으면서 저절로 습득하게 될 것이다.

#### \#
OCR은 synthetic image(인조 데이터)를 생성하는 분야가 다른 도메인에 비해 많이 발달되어 있다. 다른 도메인에서 인조 데이터를 이용해 학습하는 방법이 주류가 되지 못한 이유는 편향 때문이다. 수집이던 생성이던 현실적으로 편향(bias)이 포함될 수 밖에 없다. 하지만 인조 데이터의 경우 수집에선 발견할 수 없는 추가적인 편향이 존재한다. {{< hl-text primary >}}결국 이러한 편향은 모델의 <b>overfitting(과적합)</b>을 야기하여 성능에 강한 제약을 건다.{{< /hl-text >}}

그럼에도 불구하고 OCR에서 인조 데이터를 사용하는 이유는 인조 데이터를 사용하는 것이 **아직까지는** 모델의 성능을 높히는데 도움이 되고 있기 때문이다. 그 가장 큰 이유는 데이터의 부족이다. OCR은 annotation   난이도가 높고 오래전부터 상업적으로 서비스되고 있었기에 다른 도메인에 비해 공개된 데이터의 수가 부족하다. 논문 등에서도 모델의 평가는 실제 데이터로 하지만 모델의 학습에는 인조 데이터를 주로 이용한다.

{{< image classes="center" src="/images/OCR/1-5.png" title="Figure 5. Synthetic text images" >}}

딥 러닝에 대한 오랜 경험에 의해 OCR 인조 데이터를 처음 접했을 때 많은 의구심이 들었다. 하지만 지금은 생각이 많이 바뀌어 혹시 다른 도메인에서는 인조 데이터를 만드는 연구가 부족했던 것은 아닌지 싶을 정도이다. 왜냐하면 결국 {{< hl-text primary >}}우리의 최종 목표는 수집이던 생성이던 <b>모집단과 유사한 표본 집단</b>을 구하는 것이기 때문이다.{{< /hl-text >}} 어려운 문제일수록 경우의 수가 다양하기에 모집단과 유사한 데이터 생성 프로그램을 개발하는 것은 불가능에 가깝다. 하지만 연구가 거듭되면서 점점 그 차이를 좁혀가고 있다.

#### Reference
[1] https://www.ncloud.com/product/aiService/ocr

[2] Y. Baek et al. [Character Region Attention For Text Spotting](https://arxiv.org/abs/2007.09629)

[3] Y. Baek et al. [Character Region Awareness for Text Detection](https://arxiv.org/abs/1904.01941)

[4] J. Baek et al. [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis](https://arxiv.org/abs/1904.01906)

[5] A. Gupta et al. [Synthetic Data for Text Localisation in Natural Images](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16)
