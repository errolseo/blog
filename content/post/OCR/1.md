---
title: "[OCR] 1. Data"
date: 2022-02-15T18:37:29+09:00
categories:
- OCR
tags:
- OCR
- scene text recognition
- scene text detection
keywords:
- OCR
thumbnailImage: /images/OCR/samples.png
thumbnailImagePosition: left
summary: OCR 프로젝트를 진행하기 위해 OCR 데이터에 대해 정의합니다.
---
{{< alert warning >}}
본문의 내용은 개인적인 정리를 위해 작성되었기에 학술적이지 않습니다.  
또한 증명되지 않은 내용이 포함되어 있을 가능성이 존재합니다.
{{< /alert >}}
\
[OCR articles](/categories/ocr/)  
\
Deep learning 프로젝트를 진행하기 위해서는 그 프로젝트에 해당하는 **데이터**와 **모델**에 대한 정의가 필요합니다. 이 2 가지가 제대로 정의되지 않는다면 프로젝트는 반드시 실패한다고 개인적으로 생각합니다. 그렇기에 OCR 프로젝트를 진행하기 앞서 OCR 데이터와 OCR 모델에 대한 리서치를 각각 진행해야 하며, 이 페이지에서는 우선 {{< hl-text primary >}}OCR 데이터에 대한 내용을 다룰 것{{< /hl-text >}}입니다.  
&nbsp;&nbsp;&nbsp;&nbsp;OCR 데이터는 실제 데이터(real world text)와 인조 데이터(synthetic text) 2 종류가 존재합니다. 다른 도메인에서도 인조 데이터를 제작해서 사용하는 경우가 존재하지만, 대부분의 경우 OCR 만큼 그 의존성이 크지 않습니다. 다른 도메인에서는 최근 데이터의 부족을 해소하기 위해 인조 데이터를 사용하기보다는 자가지도(self-supervised) 학습 등을 사용하는 추세입니다.  
&nbsp;&nbsp;&nbsp;&nbsp;그럼에도 불구하고 OCR에서 인조 데이터에 의존하는 가장 큰 이유는 인조 데이터를 사용하는 것이 실제 테스트 데이터에 대한 모델의 성능에 큰 기여를 한다는 점 입니다. 그 이유에 대한 설명을 하기 위해서는 어쩔 수 없이 **모델**에 대한 내용을 말해야 합니다.
\
\
본문에서는 이제까지 광학 텍스트 인식(Optical Text Recognition)이란 단어를 사용했지만 OCR은 목적에 따라 여러 갈래로 나뉩니다. 본문에서는 **scene text**를 중심으로한 detection 및 recognition task에 대해 다루고 있습니다. Scene text란 **실외 환경에서 카메라를 사용해서 촬영한 이미지에 나타난 텍스트**라고 위키에 나와 있지만 개인적으로 {{< hl-text primary >}}문서와 같은 텍스트 중심의 물체 또는 영수증과 같은 포맷이 일정한 물체를 제외한 <b>예측하기 어려운 형태의 텍스트가 존재하는 이미지 속 텍스트</b>{{< /hl-text >}}는 전부 scene text라고 생각합니다.  
\
{{< image classes="center" src="/images/OCR/text_recognition.png" title="Scene Text Recognition [Clova AI. Deep text recognition]" >}}
{{< image classes="center" src="/images/OCR/craft.png" title="Scene Text Dectection [Clova AI. CRAFT]" >}}

언뜻 보기에는 OCR이란 이미지를 넣으면 이미지 속에 존재하는 모든 텍스트를 찾아서 디지털 정보로 변환해주는 것 같지만, recognition model은 위의 이미지 처럼 word 단위로 추론(inference)을 진행합니다. 즉, {{< hl-text primary >}}<b>recognition model</b>의 입력은 <u>scene image</u>가 아닌 <u>word box images</u>{{< /hl-text >}} 입니다. 그리고 {{< hl-text primary >}}scene image 속에서 <u>word box images</u>를 찾는 것은 <b>detection model</b>을{{< /hl-text >}} 이용합니다.  
\
{{< image classes="center" src="/images/OCR/samples.png" title="Synthtext(Synthetic text)" >}}

인조 데이터는 분명 편향(bias)을 포함하고 있습니다. 이는 많은 도메인에서 인조 데이터를 사용하지 않는 이유이기도 합니다. OCR의 경우도 마찬가지 입니다. {{< hl-text primary >}}특정 위치에 존재할 수 없는 형태의 글자가 존재하는 이슈는{{< /hl-text >}} 해결할 수 없는 문제입니다. 이는 detection model의 성능에 큰 영향을 줄 수 밖에 없습니다. 하지만 이러한 이슈는 {{< hl-text primary >}}<b>precision</b>을 감소시킬 수도 있지만 <b>recall</b>은 오히려 증가시킬 수도 있습니다.{{< /hl-text >}} 다시 말해 텍스트가 아님에도 텍스트라고 감지할 확률이 높아지지만 그것과 별개로 텍스트를 감지하는데는 도움이 됩니다.  
&nbsp;&nbsp;&nbsp;&nbsp;또한 recognition model이 detection model과 분리되어 있기에 recognition model은 인조 데이터의 편향을 적게 받습니다. 왜냐하면 recognition model의 입력은 주위 배경이 모두 날아가고 대부분이 텍스트로 채워진 이미지입니다. {{< hl-text primary >}}이게 실제로 존재할 수 있는 형태인지 불가능한 형태인지 <b>recognition model</b>이 정답을 맞추는데 크게 중요하지 않다는 것{{< /hl-text >}} 입니다. recognition model 입장에서는 오히려 더 어렵고 더 다양한 데이터를 경험할 수 있기에 큰 메리트로 작용할 수 있습니다.  
\
OCR model 중에는 dectection과 recognition 뿐만 아니라 text spotting이라는 End-to-End 모델 또한 존재합니다. Deep learning에 대한 이해도가 높은 분이라면 End-to-End 모델의 최적화는 기존 모델보다 월등히 우수한 성능을 도출할 가능성이 존재한다는 것을 인지하고 있을 것 입니다. 하지만 인조 데이터를 사용하는 OCR의 경우는 아직 detection과 recogintion을 분리하는데서 오는 장점이 성능에 큰 메리트로 작용하고 있습니다. Text spotting model을 이용한 연구들도 더러 존재하지만 개인적으로는 방대한 real world text 데이터를 구축한 것이 아니라면 사용하기 어려울 것 같습니다.  
&nbsp;&nbsp;&nbsp;&nbsp;여기까지 OCR 학습을 위해 인조 데이터를 사용하는 이유를 정리해봤습니다. 다음 장에서는 공개된 인조 데이터와 그것을 만드는 방법에 대해 다룰 예정입니다.