---
title: "[OCR] 1. Optical Text Recognition"
date: 2022-02-15T13:00:00+09:00
categories:
- OCR
tags:
- OCR
- scene text detection
- scene text recognition
- synthetic text image
keywords:
- OCR
thumbnailImage: /images/OCR/samples.png
thumbnailImagePosition: left
summary: Optical Text Recognition(OCR)의 배경 지식에 대한 정리
---)
{{< alert warning >}}
본문의 내용은 개인적인 정리를 위해 작성되었기에 학술적이지 않습니다.  
또한 증명되지 않은 내용이 포함되어 있을 가능성이 존재합니다.
{{< /alert >}}

### 1.
Optical Text Recognition(OCR)은 크게 2 가지, {{< hl-text primary >}}<b>일정한 형식</b>이 존재하는 문서 등의 이미지{{< /hl-text >}}(Fig.1) 혹은 {{< hl-text primary >}}<b>다양한 형태</b>의 일반적인 이미지{{< /hl-text >}}(Fig.2)로 나눌 수 있다.

{{< image classes="center" src="/images/OCR/1-fig1.png" title="Fig. 1: Document OCR" >}}
{{< image classes="center" src="/images/OCR/1-fig2.png" title="Fig. 2: Scene text OCR" >}}

앞으로 필자가 정리할 내용은 후자에 해당하는 scene text를 어떻게 탐지(Detection)하고 인식(Recog-nition)하는지에 대한 내용이다. 만약 본인이 하는 OCR 프로젝트가 document OCR에 가깝다면 다른 글을 찾아보는 것을 추천한다. Scene text OCR은 포맷이 일정하지 않으며, 이미지 속 텍스트의 존재 유무가 확실하지 않고, 다양한 서체(Font)나 형태(Transform)가 존재하기 때문에 성능을 높히는 것이 쉽지 않았으나 최근 많은 연구를 통해 점점 성능이 높아지고 있다.

### 2.
OCR은 detection과 recognition 두 파트로 나누어져 있다. 기본적으로 scene text detection과 scene text recognition의 서로 독립된 모델로 존재하나, scene text spotting과 같이 하나의 모델 안에 두 개의 파트로 나누어져 존재할 수도 있다.

{{< image classes="center" src="/images/OCR/1-fig3.png" title="Fig. 3: Scene text dectection" >}}
{{< image classes="center" src="/images/OCR/1-fig4.png" title="Fig. 4: Scene text recognition" >}}

Detection 모델의 경우 이미지 내에 텍스트가 존재할 만한 여러 개의 Region of Interest(RoI)를 추출한다. 그렇게 추출한 각각의 RoI들이 recogniton 모델의 입력이 된다. 두 개의 모델로 나누어서 학습하는 이유는 단순하면서 복잡하다. 기본적으로 작업의 난이도를 대폭 낮출 수 있으나 배경에 대한 정보를 소실하는 문제가 있다. 더 자세하고 정확한 내용은 OCR에 대한 지식을 쌓으면서 저절로 습득하게 된다.

### 3.
OCR은 synthetic image(인조 데이터)를 생성하는 분야가 다른 도메인에 비해 많이 발달되어 있다. 만약 {{< hl-text primary >}}세상의 모든 경우의 수(모집단)와 동일한 데이터를 수집이 아닌 <b>생성</b>할 수 있다면{{< /hl-text >}} 데이터를 수집할 이유가 사라진다. 하지만 그런 일은 불가능에 가깝다. 결국 프로그램을 이용해서 생성하는 데이터는 편향(bias)이 포함될 수 밖에 없으며, 편향이 포함된 데이터로 학습한 모델은 학습 데이터에 과적합(overfit-ting)될 수 밖에 없다.  
그럼에도 불구하고 OCR에서 인조 데이터를 사용하는 이유는 인조 데이터를 사용해서 학습하는 편이 **아직까지는** 모델의 성능을 높히는데 도움이 되고 있기 때문이다. OCR은 상업적인 이유 등으로 인해 다른 도메인에 비해 공개된 데이터의 수가 부족하고 다른 도메인에 비해 다양하고 자연스러운 합성 이미지를 생성할 수 있다. 논문 등에서도 모델의 평가는 실제 데이터로 하지만 모델의 학습에는 인조 데이터를 주로 이용한다.

{{< image classes="center" src="/images/OCR/1-fig5.png" title="Fig. 5: Synthetic text images" >}}

자연스러운 scene text image 합성을 위해 많은 연구들이 진행되었다. 그럼에도 불구하고 일반 이미지에 인공적으로 텍스트를 합성했을 때 그 이미지가 원래부터 이런 이미지였다는 느낌이 들기에는 아직 부족한 부분이 많다. 이러한 사실들은 detection model의 precision을 증가시키는데 도움이 될 수 있어도 recall은 오히려 감소시킬 수 있다. 무작위로 합성된 이미지를 학습한 detection 모델은 {{< hl-text primary >}}텍스트가 아님에도 텍스트로 볼 확률이 증가한다.{{< /hl-text >}}  
하지만 recognition의 경우 이미지 합성을 통해 더 어렵고 더 다양한 문제들을 학습하여 모델의 성능을 극대화할 수 있다. Recognition 모델의 입장에서는 인조 데이터가 실제 데이터와 유사할 필요가 없다. 오히려 더 어렵고 더 다양한 학습 데이터를 생성할 수 있다면 모델에게 많은 도움이 된다. 다만 다양하다는 부분에서 명확한 한계가 존재한다. 프로그램으로 생성하는 인조 데이터의 다양성은 결국 작성자가 정의한 기준에 국한될 수 밖에 없다.