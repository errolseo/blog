---
title: Optical Text Recognition (OCR)
date: 2022-02-22
categories:
- OCR
thumbnailImage: /images/OCR/1/1.webp
summary: OCR 개론
---
광학 문자 인식(Optical Text Recognition, OCR)은 크게 두 가지로 나눌 수 있습니다. <strong>{{<hl-text primary>}}일정한 형식을 갖는 문서 이미지{{</hl-text>}}</strong>(그림. 1) 그리고 <strong>{{<hl-text primary>}}형태가 일정하지 않은 자연 이미지{{</hl-text>}}</strong>(그림. 2)입니다.

---
{{<image classes="center" src="/images/OCR/1/1.webp">}}
> 그림 1. Document OCR<br>
[CLOVA OCR](https://www.ncloud.com/product/aiService/ocr#detail)

{{<image classes="center" src="/images/OCR/1/2.webp">}}
> 그림 2. Scene Text OCR<br>
[Youngmin Baek, et al. (2020)](https://arxiv.org/abs/2007.09629)

필자는 현재 Scene Text OCR에 대해 다루고 있습니다. Scene Text OCR은 {{<hl-text primary>}}불규칙한 텍스트 형태, 다양한 폰트, 크기, 색상, 그리고 복잡한 배경{{</hl-text>}}과 같은 여러 변수들이 존재하여, 기존의 Document OCR에 비해 인식 난이도가 훨씬 높습니다.

---
## Model
OCR은 크게 <strong>텍스트 검출(Detection)</strong>과 <strong>텍스트 인식(Recognition)</strong> 두 파트로 나뉩니다. 일반적으로 이 두 파트는 각각 독립된 모델인 Detection Model과 Recognition Model로 존재합니다.

{{<image classes="center" src="/images/OCR/1/3.webp">}}
> 그림 3. Text Detection<br>
[Youngmin Baek, et al. (2019)](https://arxiv.org/abs/1904.01941)

{{<image classes="center" src="/images/OCR/1/4.webp">}}
> 그림 4. Text Recognition<br>
[Jeonghun Baek, et al. (2019)](https://arxiv.org/abs/1904.01906)

검출과 인식 모델을 분리하여 학습하는 주된 이유는 각 단계의 목적이 다르고, 이에 따라 요구되는 입력과 출력 형태가 다르기 때문입니다. Detection 모델은 입력으로 전체 이미지를 받아 이미지 내에서 텍스트가 존재하는 영역(예: 바운딩 박스)을 찾아내는 것이 목표이며, 이를 통해 텍스트가 아닌 불필요한 배경 정보의 영향을 최소화할 수 있습니다.

반면, Recognition 모델은 Detection 모델로부터 추출된, 텍스트가 포함된 이미지 영역(예: 바운딩 박스로 잘라낸 이미지)을 입력으로 받아 해당 이미지 내의 문자를 실제 텍스트 문자열로 변환하는 것을 목표로 합니다. 이처럼 역할을 분리함으로써 각 모델은 자신의 특정 작업에 최적화된 데이터와 아키텍처로 학습될 수 있어 전체 OCR 시스템의 정확성과 효율성을 높일 수 있습니다.

---
## Data
최근 OCR 시스템 개발에 있어 <strong>합성 데이터(synthetic text image)</strong>의 활용이 선택이 아닌 필수가 되고 있습니다. 그 이유는 고품질의 실제 OCR 학습 데이터를 수집하고 수동으로 주석을 다는 과정이 많은 시간과 비용이 드는 작업이기 때문입니다. 반면 합성 데이터는 프로그래밍 방식으로 대량 생산이 가능하여, 모델 학습에 필요한 충분한 양의 데이터를 빠르게 확보할 수 있다는 큰 장점을 가집니다.

또한 실제 데이터만으로는 다양한 글꼴, 크기, 색상, 배경, 조명, 왜곡, 노이즈, 각도 등 가능한 모든 시나리오를 포괄하기 어렵습니다. 특정 시나리오를 의식해서 데이터를 수집하는게 어려울 뿐만 아니라 특정 언어, 특수 문자, 필기체, 손상된 문서 등은 애당초 해당 데이터가 부족한 경우도 존재하기 때문에 이러한 문제들을 해결하기 위해 합성 데이터를 이용하는 것은 모델 성능 향상에 기여함과 동시에 비용 효율성을 높일 수 있습니다.

게다가 민감한 정보가 포함된 실제 문서를 사용할 때 발생할 수 있는 개인정보 보안 문제 또한 합성 데이터를 사용함으로써 효과적으로 피할 수 있습니다.

{{<image classes="center" src="/images/OCR/1/5.webp">}}
> 그림 5. Synthetic text images<br>
[Ankush Gupta, et al. (2016)](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16/)

합성 데이터는 OCR 시스템 개발에 많은 이점을 제공하지만 한계점도 분명히 존재합니다. {{<hl-text primary>}}아무리 정교하게 만들어진 합성 데이터라 할지라도 현실을 완벽하게 반영하기는 어렵습니다.{{</hl-text>}} 현실에는 그림자나 광택 등 예측하기 어려운 다양한 노이즈가 존재하는데 이러한 노이즈나 왜곡을 충분히 담아내지 못할 수 있습니다. 이로 인해 합성 데이터로 학습된 모델이 실제 데이터에서 성능 저하를 보이거나 새로운 유형의 오류를 생성할 가능성이 있습니다.

또한 합성 데이터의 사용은 <strong>과적합(Overfitting) 위험</strong>이 있습니다. 합성 데이터가 실제 데이터의 분포를 충분히 반영하지 못하면, 모델이 합성 데이터의 특정 패턴에 과적합되어 실제 데이터에서의 성능이 떨어질 수 있습니다. 특히 생성 방식이 단순하거나 다양성이 부족한 경우 이러한 문제는 더욱 두드러집니다.

게다가 합성 데이터의 품질 평가가 어렵다는 점도 한계로 꼽힙니다. 생성된 합성 데이터가 현실을 얼마나 잘 대표하는지 정량적으로 평가하기 쉽지 않습니다. 단순히 시각적인 유사성만으로는 부족하며, 실제 OCR 시스템의 성능 향상으로 이어지는지 실질적인 검증이 필요합니다.

---
#### Reference
[1] Baek, Jeonghun (2019) | [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis](https://arxiv.org/abs/1904.01906)

[2] Baek, Youngmin (2019) | [Character Region Awareness for Text Detection](https://arxiv.org/abs/1904.01941)

[3] Baek, Youngmin (2020) | [Character Region Attention For Text Spotting](https://arxiv.org/abs/2007.09629)

[4] Gupta, Ankush (2016) | [Synthetic Data for Text Localisation in Natural Images](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16)

[5] NAVER Cloud Platform | [CLOVA OCR](https://www.ncloud.com/product/aiService/ocr#detail)