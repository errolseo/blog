---
title: "[OCR] Scene Text Recognition"
date: 2022-04-26T00:00:00+09:00
categories:
- OCR
tags:
- Scene Text Recognition
thumbnailImage: 
thumbnailImagePosition: right
summary: Scene Text Recognition
---
{{< alert info >}}
On writting
{{< /alert >}}
Scene Text Recognition(STR) 모델은 word box image를 입력으로 받는다. 즉, STR 모델의 입력은 

#### \#
2015년에 공개된 [Convolutional Recurrent Neural Network(CRNN)](https://arxiv.org/abs/1507.05717)은 Convolutional, Recurrent, Transcription 3 단계의 레이어로 이루어져 있다. CNN을 이용해 이미지로부터 feature를 추출하고(featurization), RNN을 이용해 feature에 sequence 정보를 추가하여(sequentialization), Connectionist Temporal Classification(CTC)을 이용해 prediction 한다.

{{< image classes="center" src="/images/OCR/5-1.png" title="Fig. 1: Convolutional recurrent neural network architecture" >}}

```python
inp = torch.randn([batch, 3, height, width]) # [b, 3, h, w]
cnn_oup = cnn_layer(inp) # [b, c_c, c_h, c_w]
rnn_inp = cnn_oup.permute(0, 3, 1, 2).view(b, c_w, c_c * c_h) # [b, c_w, c_c * c_h]
rnn_oup = rnn_layer(rnn_inp, batch_first=True) # [b, c_w, hidden_size]
pred_oup = prediction(rnn_oup) # [b, c_w, num_labels]
```
데이터의 flow를 살펴보면 꽤 직관적이다. 주목할 부분은 최종 출력이다. CTC를 위해서는 [time(sequence), label probability] 형태의 데이터가 필요하다. [c_w, num_labels]
현재까지도 다양한 모델들이 발표되고 있지만 **featurization, sequentialization, prediction**으로 이루어진 구조는 대부분의 모델에서 채용되고 있다. 

#### \#
이미지 featurization에 CNN을 사용하는 것은 대세를 넘어 지배적이었다. 최근 transformer를 이용한 모델들이 준수한 성능을 자랑하며 등장하고 있지만 [EfficientNet](https://arxiv.org/abs/1905.11946) 등의 최적화된 모델을 상회한다고 보기는 어렵다. STR은 ResNet과 같은 backbone network를 기반으로 텍스트에 특화된 featurization을 위해 추가적인 모듈을 결합하여 사용한다.

#### \#
Sequntialization에는 RNN과 transformer가 
Transformer가 등장하면서 사실상 RNN에 대한 연구는 거의 죽었다. RNN은 auto regressive 모델로 이전 입력값이 이후 입력값에 영향을 줄 수 있도록 설계되었다. 



#### Reference
[1] https://github.com/HCIILAB/Scene-Text-Recognition-Recommendations

[2] B. Shi et al. [An End-to-End Trainable Neural Network for Image-based Sequence
Recognition and Its Application to Scene Text Recognition](https://arxiv.org/abs/1507.05717)

[3] A. Graves et al. [Connectionist Temporal Classification: Labelling Unsegmented
Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)

