---
title: "[OCR] Scene Text Recognition (1)"
date: 2022-04-26T00:00:00+09:00
categories:
- OCR
tags:
- Scene Text Recognition
- CRNN
- CTC
- SRN
thumbnailImage: /images/OCR/5-2.png
thumbnailImagePosition: right
summary: CRNN, CTC, SRN
katex: true
---
만약 필자에게 기존 vision task와 Scene Text Recognition(STR)의 차이를 한 문장으로 표현해 달라고 한다면, 'sequence의 유무'라고 대답할 것 같다. sequence의 존재로 인해 STR 모델은 기존 vision classification과는 다른 prediction 형태를 갖는다. 만약 기존과 같은 형태를 가진다면 영어의 알파벳 26자의 5자 조합만 해도 $26^5$이 되어 사실상 모델 생성이 불가능하다. 한글과 한자는 경우의 수가 더 심각해진다. 위의 문제를 해결하기 위한 방법은 다양하게 존재하기 때문에 후술하는 내용에 포함시키려고 한다. STR 모델의 파이프라인에 대해 이해하고, 최종적으로 텍스트의 **seqence**에 대해 이해한다면 추후의 STR 연구에 도움이 될 것이다.

#### \#
2015년에 공개된 [Convolutional Recurrent Neural Network(CRNN)](https://arxiv.org/abs/1507.05717)은 Convolutional, Recurrent, Transcription 3 단계의 레이어로 이루어져 있다. CNN을 이용해 이미지로부터 feature를 추출하고(featurization), RNN을 이용해 feature에 sequence 정보를 추가하여(sequentialization), Connectionist Temporal Classification(CTC)을 이용해 prediction 한다.

{{< image classes="center" src="/images/OCR/5-1.png" title="Fig. 1: CRNN architecture" >}}

```python
inp = torch.randn([batch, 3, height, width]) # [b, 3, h, w]
cnn_oup = cnn_layer(inp) # [b, c_c, c_h, c_w]
rnn_inp = cnn_oup.permute(0, 3, 1, 2).view(b, c_w, c_c * c_h) # [b, c_w, c_c * c_h]
rnn_oup = rnn_layer(rnn_inp, batch_first=True) # [b, c_w, hidden_size]
pred_oup = prediction(rnn_oup) # [b, c_w, num_labels]
```

모델이 복잡해 보일 수도 있는데 데이터의 flow 자체는 단순하다. 중요한 부분은 최종 출력의 형태다. [c_w, num_labels]에는 convolutional feature의 width에 대한 softmax_value가 들어있다. 즉 이미지 feature를 가로로 1 pixel씩 쪼개어 각각이 의미하는 알파벳을 classifcation하는 것 처럼 보인다. 문제는 위 방식에는 ground truth가 존재하지 않으며, 그로 인해 수 많은 정답이 존재 가능하다는 것이다. 그럼 loss는 어떻게 구하는가.

{{< hl-text primary >}}CTC는 Dynamic Programming(DP)을 이용해 모델의 출력값이 정답이 될 수 있는 모든 확률을 계산한 후, 그 확률을 최대로 만들도록 모델을 학습시키는 방법이다.{{< /hl-text >}} 즉, 정답이 여러 개 존재한다면 그 여러 개에 해당하는 각각의 확률을 모두 구한 후, 그 합이 최대가 되도록 학습하는 것이다. 만약 CTC에 대해 자세히 알고 싶다면 https://ratsgo.github.io/speechbook/docs/neuralam/ctc를 참고하면 좋다. 


현재까지도 다양한 모델들이 발표되고 있지만 **featurization, sequentialization, prediction**으로 이루어진 구조는 대부분의 모델에서 채용되고 있다. 

#### \#
이미지 featurization에 CNN을 사용하는 것은 대세를 넘어 지배적이었다. 최근 transformer를 이용한 모델들이 준수한 성능을 자랑하며 등장하고 있지만 [EfficientNet](https://arxiv.org/abs/1905.11946) 등의 최적화된 모델을 상회한다고 보기는 어렵다. STR은 ResNet과 같은 backbone network를 기반으로 텍스트에 특화된 featurization을 위해 추가적인 모듈을 결합하여 사용한다. Featurization 파트에서 크게 특이한 점은 없었다. 하지만 STR은 이미지를 다루는 task이기 때문에 가장 근본이 되는 파트이다.

#### \#
Sequntialization 파트는 $26^5$의 복잡도를 $25*5$로 바꿔주는 역활을 한다. 텍스트 이미지에 sequence 정보 없이 알파벳 단위의 prediction이 가능한가. 이 부분에 대한 직관은 꽤나 복잡하다. 위에서 CTC를 소개했는데, attention을 이용한 Auto Regressive(AR) 모델도 존재한다.

{{< image classes="center" src="/images/OCR/5-2.png" title="Fig. 2: Structure of the SRN" >}}

CTC에서는 image feature의 구조를 어느 정도 끝까지 유지했다면, [Sequence Recognition
Network(SRN)](https://arxiv.org/abs/1603.03915)에서는 image feature를 sequence feature로 바꿔버린다. 각각 장단의 유무가 있지만 STR에 더 적합한 모델은 SRN라고 생각한다. 특히 irregular의 경우 CTC는 구조적인 한계점이 명확하다.

#### Experience
STR의 **featurization, sequentialization, prediction** 각 파트는 독립적이다. 더 좋은 featurization 방법이 있다면 쓰면 되고, 더 나은 sequentialization 방법이 있다면 쓰면 된다. 물론 각각의 성능이 최상이라고 해서 조합했을 때 최적의 성능을 보여주는 것은 아니지만 각 성능을 실험하는데 유리한 구조인 것은 틀림없다. CLOVA AI에서 각 파트의 최적화에 대한 실험을 해볼 수 있는 오픈 소스를 제공한다.

학습 데이터의 경우 직접 만들어도 되지만 LMDB로 잘 정리된 파일이 kaggle에 올라와있어 링크를 첨부한다. 라이센스에 대한 자세한 사항은 필자도 모르기 때문에 개인적인 실험 외에 사용하는 것이면 자세히 알아보고 사용하는 것이 좋다.

>   open source : https://github.com/clovaai/deep-text-recognition-benchmark  
    data : https://www.kaggle.com/datasets/nunenuh/clova-deeptext
 
\
데이터만 있다면 돌리는 것 자체는 어렵지 않을 것이다. 국내에서 상당히 유명하기 때문에 돌리는 것이 어렵다면 검색을 통해 수 많은 정보를 얻을 수 있을 것이다.

#### Reference
[1] https://github.com/HCIILAB/Scene-Text-Recognition-Recommendations

[2] B. Shi et al. [An End-to-End Trainable Neural Network for Image-based Sequence
Recognition and Its Application to Scene Text Recognition](https://arxiv.org/abs/1507.05717)

[3] B. Shi et al. [Robust Scene Text Recognition with Automatic Rectification](https://arxiv.org/abs/1603.03915)

[4] A. Graves et al. [Connectionist Temporal Classification: Labelling Unsegmented
Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)

[5] J. Baek et al. [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis](https://arxiv.org/abs/1904.01906)