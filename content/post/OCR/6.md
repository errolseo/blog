---
title: Scene Text Recognition (2/2)
date: 2022-05-10
categories:
- OCR
thumbnailImage: /images/OCR/6/2.webp
summary: About text recognition (with ABINet)
---
Scene Text Recognition(STR)의 모듈로써 Language Model(LM)을 사용해 성능을 높이는 경우가 더러 존재합니다. 경우에 따라 다르지만, 대부분 유의미한 성능 향상을 보여줍니다. 이는 우리가 다루는 텍스트가 단순히 무작위 문자의 나열이 아닌, <strong>순서에 따라 의미가 정해지는</strong> 데이터이기 때문입니다. 그리고 이러한 <strong>'언어적 지식'</strong>을 텍스트 이미지만으로 학습하는 데는 한계가 존재합니다.

---
## Linguistic
<strong>언어적 지식(Linguistic)</strong>이란 추상적인 개념을 예시를 통해 살펴보겠습니다.

만약 6면체 주사위를 두 번 던져 나오는 눈의 합이 4보다 클지 작을지 예측해야 한다면, **크다**고 예측하는 것이 합리적입니다. 주사위의 모든 면이 나올 확률이 동일하다고 가정할 때, 두 눈의 합이 4보다 클 확률이 작을 확률보다 10배나 높기 때문입니다.

텍스트 인식도 이와 마찬가지입니다.

{{<image classes="center" src="/images/OCR/6/1.webp">}}
> 그림 1. Likelihood에 따른 예측 확률 (조, 즈)<br>

위 이미지처럼 노이즈로 인해 '치즈'와 '치조' 두 가지로 모두 읽힐 수 있다고 가정해봅시다. 두 단어 모두 사전에 등재된 표준어입니다. 하지만 둘 중 하나를 정답으로 골라야 한다면, '치조'보다는 '치즈'를 고르는 사람이 훨씬 많을 것입니다. 과연 이 선택은 합리적인 근거가 있을까요?

데이터를 통해 확인해 보겠습니다.

<strong>2009~2018년 신문 기사 말뭉치 분석 (데이터 출처: 모두의 말뭉치)</strong>
1. 단일 글자(1-gram) 빈도:
    - '조' : 11,150,298회
    - '즈' : 1,104,950회
    - '조'가 '즈'보다 약 10.1배 많이 사용됨
2. 연속 두 글자(2-gram) 빈도:
    - '치조' : 1,070,574회
    - '치즈' : 115,125회
    - '치조'가 '치즈'보다 약 9.3배 많이 사용됨
3. 단일 단어 빈도:
    - '치조' : 0회
    - '치즈' : 3,804회
    - '치즈'만 단일 단어로 사용됨

신문 기사 말뭉치에서 단순히 글자 '조'는 '즈'보다 10배 넘게 많이 쓰였습니다. 심지어 '치'라는 글자 바로 뒤에 온다는 조건('치조' vs '치즈')에서도 '치조'가 9배 이상 많이 등장했습니다. 이 데이터만 보면, 이미지를 '치조'로 인식하는 것이 더 확률이 높아 보입니다.

하지만 두 글자가 모여 하나의 단어로 사용되는 경우는 이야기가 완전히 달라집니다. 해당 표본 집단에서 '치조'가 단일 단어로 사용된 횟수는 0번인 반면, '치즈'는 3,804번이나 사용되었습니다.

즉, 이 이미지가 '치'로 시작하는 단일 단어 문맥(context)이 주어지면 '치즈'라고 예측하는 편이 정답일 확률이 압도적으로 높은 것입니다. 이것이 바로 STR 모델이 이미지 정보만으로는 파악하기 어려운 <strong>언어적 지식</strong>이며, Language Model이 이러한 확률적 문맥을 보정해주는 역할을 합니다.

---
## ABINet
LM이 하는 일은 어디까지나 <strong>보정(calibration)</strong>입니다. 그림 1의 예시처럼 노이즈가 심한 이미지는 시각 정보(vision model)만으로 정확한 예측이 불가능할 수 있습니다. 이때 LM은 언어적 확률을 제공하여, 모델이 '치조'와 '치즈' 같은 선택의 갈림길에 놓였을 때 더 가능성이 높은 정답을 선택하도록 이끌어줍니다. LM이 정답을 직접 예측한다기보다는, 정답일 확률을 보정하는 것입니다. 최종적으로는 이미지를 통한 예측 확률과 LM의 예측 확률이 결합되어 최적의 정답을 도출해냅니다.

물론 이상적인 모델은 LM 없이도 시각 정보만으로 모든 언어적 지식까지 학습하는 것일 겁니다. 하지만 현실적으로는 매우 어렵습니다. LM은 대규모 텍스트 말뭉치로 학습하지만, STR 모델은 텍스트 이미지로 학습하기 때문입니다. LM이 학습하는 방대한 양의 텍스트와 동일한 규모의 이미지 데이터를 구하고, 이를 STR 모델에 모두 학습시키는 것은 현실적으로 불가능에 가깝습니다.

{{<image classes="center" src="/images/OCR/6/2.webp">}}
> 그림 2. (a) Coupled language model / (b) ABINet autonomous language model<br>
[Shancheng Fang, et al. (2021)](https://arxiv.org/abs/2103.06495)

그림 2에서 가장 주목할 부분은 LM의 입력값입니다. (a)는 이미지 특징(image feature)을 LM의 입력으로 사용하지만, (b)는 텍스트(text)를 입력으로 받습니다. 이 구조적 차이 덕분에, (b)는 거대한 텍스트 말뭉치로 미리 학습된 pre-trained LM을 STR 모델에 결합하는 것을 가능하게 합니다. 이는 곧, 모델 외부에 존재하는 방대한 언어적 지식을 효과적으로 주입할 수 있다는 의미입니다.

---
## Conclusion
Language Model(LM)의 기본 원리는 위에서 다룬 통계적 지식에 기반합니다. LM은 단어들의 sequence에 대한 확률을 기억하고 단어 조합을 학습합니다. 예를 들어, '감자튀김'이란 단어는 '감자'와 '튀김'의 합성어입니다. 이런 시맨틱(semantic) 정보를 STR 모델이 scene text image를 통해 자체적으로 학습하는 것은 현재로서는 불가능에 가깝습니다.

STR 모델은 단순히 word box 안의 문자를 텍스트로 변환할 뿐인데, 왜 언어적 의미까지 알아야 하는지에 대한 의문을 가질 수도 있습니다. 사실 문자의 시맨틱을 이해하는 것이 STR 모델에 정확히 어떤 영향을 주는지는 명확히 추적하기는 어렵습니다. 하지만 확실한 것은, 수많은 텍스트와 그 언어적 지식을 학습하는 것은 어떤 형태로든 STR 모델에 도움이 된다는 것이 실험을 통해 증명되고 있습니다.

LM은 어디까지나 <strong>보정</strong>의 역할입니다. Graph Convolutional Network for Textual Reasoning(GTR) 같은 논문에서는, STR을 보정하는 LM을 다시 보정하는 GTR을 개발하여 발표하기도 했습니다. 이러한 보정 모듈들은 임시방편일 수 있습니다. 아마 머신 러닝 엔지니어와 사이언티스트들이 이상적으로 생각하는 모습은 아닐 것입니다. 하지만 지금 당장은 <strong>선택이 아닌 필수</strong>라고 생각합니다.

---
#### Reference
Fang, Shancheng (2021) | [Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition](https://arxiv.org/abs/2103.06495)

He, Yue (2021) | [Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition](https://arxiv.org/abs/2112.12916)

---