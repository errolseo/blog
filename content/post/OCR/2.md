---
title: "[OCR] MJSynth, SynthText"
date: 2022-03-08T00:00:00+09:00
categories:
- OCR
tags:
- Synthetic text image
thumbnailImage: /images/OCR/2-fig1.png
thumbnailImagePosition: right
summary: Synthetic text image (1) - 기존 방법
katex: true
---
{{< hl-text primary >}}딥 러닝 프로젝트를 위해서는 <b>데이터</b>와 <b>모델</b>을 확보할 필요가 있다.{{< /hl-text >}} 만약 독자가 OCR을 위해 대량의 scene text image를 annotation할 자금이나 인력을 보유하고 있다면 인조 데이터에 대해 다룬 이 글은 별로 도움이 되지 않을 수도 있다. 하지만 그렇지 않다면 이 글은 독자에게 필수적인 내용이 될 것이다.

#### \#
[MJSynth(MJ)](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c/)는 word box image를 생성하는 이미지 합성 엔진이자 그것을 이용해서 만든 데이터셋을 말한다. MJ는 비교적 간단한 방법들을 이용했지만 **대량의 데이터**를 생성해 냈고 scene text recognition(STR) 모델의 성능에 크게 기여하였다.

{{< image classes="center" src="/images/OCR/2-fig1.png" title="Fig. 1: MJSynth pipeline" >}}

**1. Font rendering**
- [Google Fotns](https://fonts.google.com/)에서 다운로드한 1,400개의 폰트
- 자간(kerning), 두께(weight), 밑줄(underline) 등의 속성
- 사전 정의된 90k words의 dictionary $\mathcal{W}$
- Horizontal bottom, random curve 등의 형태 변형

**2. Border/shadow rendering**
- Inset/outset border, shadow 등

**3. Base coloring**
- 외부 데이터에서 추출한 3색 1쌍의 color map

**4. Projective distortion**
{{< image classes="center" src="/images/OCR/2-fig2.png" title="Fig. 2: Projective transformation" >}}  

**5. Natural data blending**
- ICDAR 2003 and SVT 등의 실제 이미지와 합성 [(Blend mode wikipedia)](https://en.wikipedia.org/wiki/Blend_modes)

**6. Noise**
- Gaussian noise, blur, jpeg 손실 압축 왜곡 등의 노이즈

2014년에 만들어진 MJ 데이터는 scene text image는 아니기에 별도로 학습된 scene text detection(STD) 모델이 필요하다는 치명적인 단점이 존재한다. 그렇지만 MJ의 기본적인 방향성은 후에 이루어진 많은 연구에 영향을 주었다.

#### \#
[SynthText(ST)](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16/)의 기본적인 pipeline은 MJ와 유사하다. 다만 추가적인 기술을 이용해 양적인 측면과 질적인 측면 모두 양호한 scene text image를 생성해 냈다. ST는 MJ와 함께 많은 논문에서 pre-trained 모델을 학습하는데 사용되고 있다.  
{{< hl-text primary >}}인조 데이터인 표본집단 $\mathrm{n}$의 이상적인 목표는 모집단 $\mathrm{N}$과 최대한 <b>유사</b>해지는 것이며, 그 과정에서 모집단과 동일한 수준의 <b>다양성</b>을 확보해야 한다.{{< /hl-text >}} 반대로 말하면 모집단에 존재할 수 없는 데이터를 포함하고 있거나, 한 쪽으로 편향된 학습 데이터는 모델의 성능에 악영향을 줄 것이다. ST는 이런 문제점을 해결하기 위해 [poisson image editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)을 이용해 다양한 배경 위에 텍스트가 자연스럽게 녹아들 수 있도록 했고, [gPb-UCM](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf)을 통해 얻은 이미지의 경계선을 이용해 텍스트의 위치가 자연스러워지도록 제어했다.

{{< image classes="center" src="/images/OCR/2-fig3.png" title="Fig. 3: Poisson Image Editing (JM Di Martino et al.)" >}}
{{< image classes="center" src="/images/OCR/2-fig4.png" title="Fig. 4: Contour Detection and Hierarchical Image Segmentation (Pablo Arbelaez et al.)" >}}
{{< image classes="center" src="/images/OCR/2-fig5.png" title="Fig. 5: (좌) ST 예시 이미지 / (우) 현실에선 존재할 수 없는 텍스트" >}}

실제 ST의 데이터는 Fig.5의 예시에 나와있는 이미지만큼 훌륭한 편은 아니다. 하지만 메커니즘 상으론 예시와 같은 결과가 나올 수 있으며 예시의 이미지는 ST가 목표로 하고 있는 방향성을 정확히 보여준다. 필자가 파워포인트로 합성한 Fig.5의 우측 이미지와 비교해 보면 차이를 확연하게 알 수 있다. 눈으로는 와닿는 이 사실을 논리적으로 설명하기 위해서는 위에서 말한 **다양성**과 **유사성**에 대한 고찰이 필요하다.

#### \#
데이터의 다양성은 알파이자 오메가다. 사실 모집단 수준의 다양성을 확보할 수 있다면 유사성은 문제가 되지 않는다. {{< hl-text primary >}}시험 범위 안의 내용을 완전히 이해했다면 만점을 받을 것이며, 시험 범위 밖의 내용을 <b>추가적으로</b> 학습하는 것은 결과에 영향을 주지 않는다.{{< /hl-text >}} 문제는 우리가 정확한 시험 범위를 알 수 없다는 점이다. 게다가 만약에 알 수 있다 해도 시험 범위 전체를 이해하는 것은 사실상 불가능하다. 그렇기에 가능한 시험 범위 위주로 공부할 수 박에 없다. 결국 유사성이란 표준화(standardization)와 비슷한 내용이다. 다만 현실의 데이터를 수집하는 것이 아닌 가상의 데이터를 생성하는 것이기에 노이즈를 제어하는 것이 쉽지 않고 그 중요성이 더욱 커지게 된다. 간단한 예시를 통해 직관적으로 알아보자.

{{< image classes="center" src="/images/OCR/2-fig6.png" title="Fig. 6: (좌) 타밀 문자 로고 / (우) 한글 로고" >}}
{{< image classes="center" src="/images/OCR/2-fig7.png" title="Fig. 7: 타밀어 스타벅스 간판" >}}

타밀 문자를 접해본 적이 없다면 Fig.6의 타밀 문자 로고를 보고 글자라고 생각하기 어려울 수 있다. 반대로 한글을 접해본 적 없는 외국인이라면 한국어 로고를 보고 단순한 그림이라고 생각하기 쉽다. 하지만 우리는 처음보는 언어라 하더라도 Fig.7의 간판을 보고 높은 확률로 글자일 것이라 예측할 수 있다. {{< hl-text primary >}}글자가 존재해야 할 곳에 무엇가 존재한다면 <b>식별이 불가능하더라도</b> 마땅히 글자라고 예측할 수 있다.{{< /hl-text >}} 그리고 이러한 종류의 통계적 추론은 대부분 경험을 통해 축적된 데이터에 절대적으로 의존적이다.  
사람들은 현실의 풍경에서 그러한 지식을 학습하지만 모델은 학습 데이터를 통해서만 배울 수 있다. 사람들에게 학습 데이터의 노이즈는 그저 표본(sample)의 노이즈에 불과하지만 모델에게는 표본이 전부이기에 노이즈는 절대적 진실이 되버린다. 결국 데이터의 노이즈는 문제의 난이도를 높히며 혼란을 가중시킨다.

#### \#
쓰레기는 적으면 적을수록 좋지만 쓰레기를 안 만들 수는 없다. 샴푸가 환경에 안 좋다 해서 머리를 안 감을 수 는 없다. 데이터의 노이즈도 마찬가지다. 우리는 데이터가 필요하고 데이터를 많이 생성하려 하면 할수록 노이즈의 양도 증가한다. 그렇기에 유사하지 않은 데이터가 무조건 나쁘다고 할 수는 없다.  
만약 풀고자 하는 문제가 어려우면 어려울수록 loss의 수렴을 위해 필요한 데이터의 최소량이 크다. 수렴 자체가 안되는데 성능이 무슨 소용인가. 이런 경우는 유사성의 중요도가 비교적 낮아진다. 그리고 모집단과 유사하지 않더라도 다양한 데이터는 모델의 precision 향상에는 도움이 되기도 한다. 배운 적 없는 새로운 경험은 기존에 풀지 못하던 문제를 푸는데 도움을 줄 수도 있기 때문이다. 하지만 보통의 경우 precision의 상승 폭보다 recall의 하락 폭이 크기에 precision을 위해 노이즈를 학습시킨 다는 것은 있을 수 없다.  
이상적으로는 다양성과 유사성 둘을 동시에 확보하는 것이 타당하다. 하지만 쓰레기 없이 파티를 할 수는 없는 법. 그 trade-off에 대한 고민은 필수 불가결하다.

#### Experience
Dockerfile
```dockerfile
FROM nvcr.io/nvidia/pytorch:21.12-py3

ENV LD_PRELOAD=/opt/conda/lib/libmkl_core.so:/opt/conda/lib/libmkl_sequential.so

RUN apt-get update && apt-get install -y libsm6 libxext6 libxrender-dev && rm -rf /var/lib/apt/lists/*
RUN pip install h5py pygame
RUN git clone -b python3 https://github.com/ankush-me/SynthText.git
```

#### Reference
[1] M. Jaderberg et al. [Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c)  
[2] A. Gupta et al. [Synthetic Data for Text Localisation in Natural Images](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16)  
[3] P. Perez et al. [Poisson Image Editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)  
[4] P. Arbelaez et al. [Contour Detection and Hierarchical Image Segmentation](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf)
