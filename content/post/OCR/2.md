---
title: "[OCR] Synthetic text image (1)"
date: 2022-02-22T13:00:00+09:00
categories:
- OCR
tags:
- MJSynth
- SynthText
keywords:
- OCR
thumbnailImage: /images/OCR/2-fig1.png
thumbnailImagePosition: left
summary: MJSynth / SynthText
katex: true
---
{{< alert warning >}}
본문의 내용은 개인적인 정리를 위해 작성되었기에 학술적이지 않습니다.  
또한 증명되지 않은 내용이 포함되어 있을 가능성이 존재합니다.
{{< /alert >}}

### 1.
딥 러닝 프로젝트를 위해서는 데이터와 모델을 확보할 필요가 있다. 만약 독자가 OCR을 위해 대량의 scene text image를 annotation할 자금이나 인력을 보유하고 있다면 인조 데이터에 대해 다룬 이 글은 별로 도움이 되지 않을 수도 있다. 하지만 그렇지 않다면 이 글은 독자에게 필수적인 내용이 될 것이다.

### 2.
[MJSynth(MJ)](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c/)는 text image를 생성하는 합성 엔진이자 그것을 이용해서 만든 데이터셋을 말한다. MJ는 기본적인 방법만을 이용해서 대량의 text image를 생성해 recognition 모델의 성능에 크게 기여하였다.

{{< image classes="center" src="/images/OCR/2-fig1.png" title="Fig. 1: MJSynth pipeline" >}}

**1. Font rendering**
- [Google Fotns](https://fonts.google.com/)에서 다운로드한 1,400개의 폰트 중 선택
- 자간(kerning), 두께(weight), 밑줄(underline) 등 폰트 속성의 추가
- 사전 정의된 90k words의 dictionary $\mathcal{W}$에서 단어 선택
- Horizontal bottom, random curve 등의 transform 선택

**2. Border/shadow rendering**
- Inset/outset border, shadow 등 추가

**3. Base coloring**
- 외부 데이터에서 추출한 color map을 바탕으로 색 설정

**4. Projective distortion**
{{< image classes="center" src="/images/OCR/2-fig2.png" title="Fig. 2: Projective transformation" >}}  

**5. Natural data blending**
- ICDAR 2003 and SVT 등의 실제 이미지와 합성 [(Blend mode wikipedia)](https://en.wikipedia.org/wiki/Blend_modes)

**6. Noise**
- Gaussian noise, blur, jpeg 손실 압축 왜곡 등의 noise 추가

2014년에 만들어진 MJ 데이터는 scene text image는 아니기에 scene text detection을 위해서 별도의 데이터를 필요하다는 치명적인 단점이 존재한다. 그렇지만 MJ는 대용량 OCR 인조 데이터의 출발점을 끊었고 기본적인 방향성은 후에 이루어진 많은 연구에 영향을 주었다.

### 3.
[SynthText(ST)](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16/)의 기본적인 pipeline은 MJ와 유사하다. 다만 추가적인 기술을 이용해 양적인 측면과 질적인 측면 모두 양호한 **scene text image**를 생성해 냈다. ST는 MJ와 함께 많은 논문에서 pre-trained 모델을 학습하는데 사용하고 있다.  
인조 데이터인 표본집단 $\mathrm{n}$의 이상적인 목표는 모집단 $\mathrm{N}$과 최대한 **유사**해지는 것이며, 그 과정에서 모집단과 동일한 수준의 **다양성**을 확보해야 한다. 반대로 말하면 모집단에서 존재할 수 없는 데이터를 포함하고 있거나, 한 쪽으로 편향된 학습 데이터는 모델의 성능에 악영향을 줄 것이다. ST는 [poisson image editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf), [gPb-UCM](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf) 등을 이용해 자연스러운 이미지, 즉 모집단과 유사한 이미지를 생성해냈다. 

{{< image classes="center" src="/images/OCR/2-fig3.png" title="Fig. 3: Poisson Image Editing (JM Di Martino et al.)" >}}
{{< image classes="center" src="/images/OCR/2-fig4.png" title="Fig. 4: Contour Detection and Hierarchical Image Segmentation (Pablo Arbelaez et al.)" >}}
{{< image classes="center" src="/images/OCR/2-fig5.png" title="Fig. 5: (좌) ST 예시 이미지 / (우) 현실에선 존재할 수 없는 텍스트" >}}


데이터의 다양성은 데이터 생성뿐만 아니라 데이터 수집에서도 당연한 이야기이므로 자세한 설명은 넘어가겠다. 문제는 모집단과의 유사성이다. 이 부분은 쉽게 설명 가능한 단순한 문제는 아니다.

{{< image classes="center" src="/images/OCR/2-fig6.png" title="Fig. 6: (좌) 타밀어 로고 / (우) 한글 로고" >}}
{{< image classes="center" src="/images/OCR/2-fig7.png" title="Fig. 7: 타밀어 스타벅스 간판" >}}

타밀어를 접해본 적이 없다면 fig.6의 타밀어 로고를 보고 글자라고 생각하기 어려울 수 있다. 반대로 한글을 접해본 적 없는 외국인이라면 한국어 로고를 보고 단순한 그림이라고 생각하기 쉽다. 하지만 우리는 처음보는 언어라 하더라도 fig.7의 간판을 보고 높은 확률로 글자일 것이라 예측할 수 있다. {{< hl-text primary >}}글자가 존재해야할 곳에 무엇가 존재한다면 <b>식별이 불가능하더라도</b> 글자라고 예측할 수 있다{{< /hl-text >}}는 것이다. 이것 외에도 모집단과 유사한 데이터를 통해 학습할 수 있는 부분이 많다.  
하지만 유사하지 않은 데이터가 무조건 나쁜 것은 아니다. Trade-off가 존재한다. 전 장에서도 말했듯이 모델의 precision 향상에는 도움이 될 수도 있다. 즉 경우에 따라서 전혀 고려할 필요가 없을 수 있다.

#### Experience
Environments (Dockerfile)
```
FROM nvcr.io/nvidia/pytorch:21.12-py3

ENV LD_PRELOAD=/opt/conda/lib/libmkl_core.so:/opt/conda/lib/libmkl_sequential.so

RUN apt-get update && apt-get install -y libsm6 libxext6 libxrender-dev && rm -rf /var/lib/apt/lists/*
```


Main dependencies
```
pygame==2.0.0, opencv (cv2), PIL (Image), numpy, matplotlib, h5py, scipy
```
Main dependencies의 pygame을 제외한 대부분의 라이브러리는 아마 익숙할 것이라 생각한다. 

{{< tabbed-codeblock "gen/test.py" "https://github.com/ankush-me/SynthText/blob/master/gen.py" >}}
<!-- tab python -->
x = a
<!-- endtab -->
{{< /tabbed-codeblock >}}
