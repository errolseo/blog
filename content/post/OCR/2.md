---
title: "[OCR] Synthetic Text Image (1)"
date: 2022-03-08T00:00:00+09:00
categories:
- OCR
tags:
- Synthetic Text Image
- MJSynth
- SynthText
thumbnailImage: /images/OCR/2-1.png
thumbnailImagePosition: right
summary: MJSynth, SynthText
katex: true
---
{{< hl-text primary >}}딥 러닝 프로젝트를 위해서는 <b>데이터</b>와 <b>모델</b>을 확보할 필요가 있다.{{< /hl-text >}} 만약 독자가 OCR을 위해 대량의 scene text image를 annotation할 자금이나 인력을 보유하고 있다면 인조 데이터에 대해 다룬 이 글은 별로 도움이 되지 않을 수도 있다. 하지만 그렇지 않다면 이 글은 독자에게 필수적인 내용이 될 것이다.

#### \#
[MJSynth(MJ)](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c/)는 word box image를 생성하는 이미지 합성 엔진이자 그것을 이용해서 만든 데이터셋을 말한다. MJ는 비교적 간단한 방법들을 이용하여 **대량의 데이터**를 생성해냈다. 데이터 생성 파이프라인은 Font rendering, Border/shadow rendering, Base coloring, Projective distortion, Natural data blending, Noise의 총 6단계로 논문에 소개되어 있다. 각 모듈들의 사용처는 직관적이지만 자세한 메커니즘은 꽤 복잡할 수도 있다.

{{< image classes="center" src="/images/OCR/2-1.png" title="Fig. 1: MJSynth pipeline" >}}

1\. Font rendering
- [Google Fotns](https://fonts.google.com/)에서 다운로드한 1,400개의 폰트
- 자간(kerning), 두께(weight), 밑줄(underline) 등의 속성
- 사전 정의된 90k words의 dictionary $\mathcal{W}$
- Horizontal bottom, random curve 등의 형태 변형

2\. Border/shadow rendering
- Inset/outset border, shadow 등

3\. Base coloring
- 외부 데이터에서 추출한 3색 1쌍의 color map
- 글자, 배경 및 기타 여러 요소들의 색상을 정하는데 사용

4\. Projective distortion

{{< image classes="center" src="/images/OCR/2-2.png" title="Fig. 2: Projective transformation" >}}

5\. Natural data blending
- ICDAR 2003 and SVT 등의 실제 이미지와 합성 [(Blend mode wikipedia)](https://en.wikipedia.org/wiki/Blend_modes)

6\. Noise
- Gaussian noise, blur, jpeg 손실 압축 왜곡 등의 노이즈

2014년에 만들어진 MJ 데이터는 scene text image는 아니기에 별도로 학습된 scene text detection(STD) 모델이 필요하다는 치명적인 단점이 존재한다. 하지만 scene text recognition(STR) 모델의 성능에 크게 기여하였고, 그 기본적인 방향성은 후에 이루어진 많은 연구에 영향을 주었다.

#### \#
[SynthText(ST)](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16/)의 기본적인 pipeline은 MJ와 유사하다. 다만 추가적인 기술을 이용해 양적인 측면과 질적인 측면 모두 양호한 scene text image를 생성해 냈다. ST는 MJ와 함께 많은 논문에서 pre-trained 모델을 학습하는데 사용되고 있다.

{{< hl-text primary >}}표본집단 $\mathrm{n}$(인조 데이터)의 이상적인 목표는 모집단 $\mathrm{N}$과 최대한 <b>유사</b>해지는 것이며, 그 과정에서 모집단과 동일한 수준의 <b>다양성</b>을 확보해야 한다.{{< /hl-text >}} 반대로 말하면 모집단에 존재할 수 없는 데이터를 포함하고 있거나, 한 쪽으로 편향된 학습 데이터는 모델의 성능에 악영향을 줄 것이다. ST는 이런 문제점을 해결하기 위해 [poisson image editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)을 이용해 다양한 배경 위에 텍스트가 자연스럽게 녹아들 수 있도록 했고, [gPb-UCM](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf)을 통해 얻은 이미지의 경계선을 이용해 텍스트의 위치가 자연스러워지도록 제어했다.

{{< image classes="center" src="/images/OCR/2-3.png" title="Fig. 3: Poisson Image Editing (JM Di Martino et al.)" >}}
{{< image classes="center" src="/images/OCR/2-4.png" title="Fig. 4: Contour Detection and Hierarchical Image Segmentation (Pablo Arbelaez et al.)" >}}
{{< image classes="center" src="/images/OCR/2-5.png" title="Fig. 5: (좌) ST 예시 이미지 / (우) 현실에선 존재할 수 없는 텍스트" >}}

메커니즘 상으론 Fig.5의 예시와 같은 결과가 나올 수도 있지만, 모든 결과가 예시처럼 훌륭하진 않다. 하지만 예시의 이미지는 ST가 목표로 하고 있는 방향성을 정확히 보여준다. 필자가 파워포인트로 합성한 Fig.5의 우측 이미지와 비교해 보면 차이를 확연하게 알 수 있다. 눈으로는 와닿는 이 사실을 논리적으로 설명하기 위해서는 위에서 말한 **다양성**과 **유사성**에 대한 고찰이 필요하다.

#### \#
데이터의 다양성은 알파이자 오메가다. 사실 모집단 수준의 다양성을 확보할 수 있다면 유사성은 문제가 되지 않는다. {{< hl-text primary >}}시험 범위 안의 내용을 완전히 이해했다면 만점을 받을 것이며, 시험 범위 밖의 내용을 <b>추가적으로</b> 학습하는 것은 결과에 영향을 주지 않는다.{{< /hl-text >}} 문제는 우리가 정확한 시험 범위를 알 수 없다는 점이다. 게다가 안다고 해도 시험 범위 전체를 이해하는 것은 사실상 불가능하다.

그렇기 때문에 데이터의 유사성이 중요해진다. 간단한 예시를 통해 직관적으로 알아보자.

{{< image classes="center" src="/images/OCR/2-6.png" title="Fig. 6: (좌) 타밀 문자 로고 / (우) 한글 로고" >}}
{{< image classes="center" src="/images/OCR/2-7.png" title="Fig. 7: 타밀어 스타벅스 간판" >}}

타밀 문자를 접해본 적이 없다면 Fig.6의 타밀 문자 로고를 보고 글자라고 생각하기 어려울 수 있다. 반대로 한글을 접해본 적 없는 외국인이라면 한국어 로고를 보고 단순한 그림이라고 생각하기 쉽다. 하지만 우리는 처음보는 언어라 하더라도 Fig.7의 간판을 보고 **식별이 불가능하더라도** 높은 확률로 글자일 것이라 예측할 수 있다. 연속성을 가진 무언가가 글자가 위치할 수 있는 곳에 존재하기 때문이다. {{< hl-text primary >}}이러한 <b>일반화(generalization)</b>된 추상적인 지식이 바로 데이터의 유사성이 중요한 이유다.{{< /hl-text >}}

우리는 '글자가 위치할 수 있는 곳'에 대해 정의한 적이 없어도 경험을 통해 학습한 사전 지식에 의해 어렴풋이 그 개념을 추상적으로 이해하고 있다. 이 능력에 의해 우리는 학습하지 않은 시험 범위의 문제도 얼추 맞출 수 있다. 그 말인즉 다양성의 부족으로 인한 손실을 유사성이 어느 정도 메꿔줄 수 있다는 것이다.

데이터 수집의 경우 데이터의 편향이 있을지언정 그 데이터는 모집단 내의 데이터가 확실하다. 하지만 데이터 생성의 경우 모집단에선 존재할 수 없는 형태의 데이터를 생성할 가능성이 존재한다. Fig.5의 우측 이미지처럼 일반적이지 않은 데이터를 계속해서 학습하면 모델은 결국 '글자가 위치할 수 있는 곳', 더 나아가서는 텍스트에 대한 추상화에 실패할 것이다. 

#### Experience
Dockerfile
```dockerfile
FROM nvcr.io/nvidia/pytorch:21.12-py3

ENV LD_PRELOAD=/opt/conda/lib/libmkl_core.so:/opt/conda/lib/libmkl_sequential.so

RUN apt-get update && apt-get install -y libsm6 libxext6 libxrender-dev && rm -rf /var/lib/apt/lists/*
RUN pip install h5py pygame
RUN git clone -b python3 https://github.com/ankush-me/SynthText.git
```

#### Reference
[1] M. Jaderberg et al. [Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c)

[2] A. Gupta et al. [Synthetic Data for Text Localisation in Natural Images](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16)

[3] P. Perez et al. [Poisson Image Editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)

[4] P. Arbelaez et al. [Contour Detection and Hierarchical Image Segmentation](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf)
