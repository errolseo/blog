---
title: "[OCR] Synthetic text image (1)"
date: 2022-03-08T00:00:00+09:00
categories:
- OCR
tags:
- mjsynth
- synthtext
thumbnailImage: /images/OCR/2-fig1.png
thumbnailImagePosition: right
summary: mjsynth / synthtext
katex: true
---
### 1.
딥 러닝 프로젝트를 위해서는 데이터와 모델을 확보할 필요가 있다. 만약 독자가 OCR을 위해 대량의 scene text image를 annotation할 자금이나 인력을 보유하고 있다면 인조 데이터에 대해 다룬 이 글은 별로 도움이 되지 않을 수도 있다. 하지만 그렇지 않다면 이 글은 독자에게 필수적인 내용이 될 것이다.

### 2.
[MJSynth(MJ)](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c/)는 word box image를 생성하는 이미지 합성 엔진이자 그것을 이용해서 만든 데이터셋을 말한다. MJ는 기본적인 방법만을 이용해서 대량의 데이터를 생성해 recognition 모델의 성능에 크게 기여하였다.

{{< image classes="center" src="/images/OCR/2-fig1.png" title="Fig. 1: MJSynth pipeline" >}}

**1. Font rendering**
- [Google Fotns](https://fonts.google.com/)에서 다운로드한 1,400개의 폰트 중 선택
- 자간(kerning), 두께(weight), 밑줄(underline) 등 폰트 속성의 추가
- 사전 정의된 90k words의 dictionary $\mathcal{W}$에서 단어 선택
- Horizontal bottom, random curve 등의 transform 선택

**2. Border/shadow rendering**
- Inset/outset border, shadow 등 추가

**3. Base coloring**
- 외부 데이터에서 추출한 color map을 바탕으로 색 설정

**4. Projective distortion**
{{< image classes="center" src="/images/OCR/2-fig2.png" title="Fig. 2: Projective transformation" >}}  

**5. Natural data blending**
- ICDAR 2003 and SVT 등의 실제 이미지와 합성 [(Blend mode wikipedia)](https://en.wikipedia.org/wiki/Blend_modes)

**6. Noise**
- Gaussian noise, blur, jpeg 손실 압축 왜곡 등의 noise 추가

2014년에 만들어진 MJ 데이터는 scene text image는 아니기에 scene text detection을 위해서 별도의 데이터가 필요하다는 치명적인 단점이 존재한다. 그렇지만 MJ의 기본적인 방향성은 후에 이루어진 많은 연구에 영향을 주었다.

### 3.
[SynthText(ST)](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16/)의 기본적인 pipeline은 MJ와 유사하다. 다만 추가적인 기술을 이용해 양적인 측면과 질적인 측면 모두 양호한 scene text image를 생성해 냈다. ST는 MJ와 함께 많은 논문에서 pre-trained 모델을 학습하는데 사용되고 있다.  
{{< hl-text primary >}}인조 데이터인 표본집단 $\mathrm{n}$의 이상적인 목표는 모집단 $\mathrm{N}$과 최대한 <b>유사</b>해지는 것이며, 그 과정에서 모집단과 동일한 수준의 <b>다양성</b>을 확보해야 한다.{{< /hl-text >}} 반대로 말하면 모집단에 존재할 수 없는 데이터를 포함하고 있거나, 한 쪽으로 편향된 학습 데이터는 모델의 성능에 악영향을 줄 것이다. ST는 이런 문제점을 해결하기 위해 [poisson image editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)을 이용해 다양한 배경 위에 텍스트가 자연스럽게 녹아들 수 있도록 했고, [gPb-UCM](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf)을 이용해 이미지의 경계선을 구한 후 텍스트의 위치가 자연스러워지도록 제어했다. 

{{< image classes="center" src="/images/OCR/2-fig3.png" title="Fig. 3: Poisson Image Editing (JM Di Martino et al.)" >}}
{{< image classes="center" src="/images/OCR/2-fig4.png" title="Fig. 4: Contour Detection and Hierarchical Image Segmentation (Pablo Arbelaez et al.)" >}}
{{< image classes="center" src="/images/OCR/2-fig5.png" title="Fig. 5: (좌) ST 예시 이미지 / (우) 현실에선 존재할 수 없는 텍스트" >}}

실제 ST의 데이터는 Fig.5의 예시에 나와있는 이미지만큼 훌륭한 편은 아니다. 하지만 메커니즘 상으론 예시와 같은 결과가 나올 수 있으며 예시의 이미지는 ST가 목표로 하고 있는 방향성을 정확히 보여준다. 필자가 파워포인트로 합성한 Fig.5의 우측 이미지와 비교해 보면 차이를 확연하게 알 수 있다. 눈으로는 와닿는 이 사실을 논리적으로 설명하기 위해서는 위에서 말한 **다양성**과 **유사성**에 대한 고찰이 필요하다.

### 4.
데이터의 다양성은 데이터 생성뿐만 아니라 데이터 수집에서도 당연한 이야기이므로 자세한 설명은 넘어가겠다. 문제는 모집단과의 유사성이다. 이 부분은 쉽게 설명 가능한 단순한 문제는 아니다.

{{< image classes="center" src="/images/OCR/2-fig6.png" title="Fig. 6: (좌) 타밀 문자 로고 / (우) 한글 로고" >}}
{{< image classes="center" src="/images/OCR/2-fig7.png" title="Fig. 7: 타밀어 스타벅스 간판" >}}

타밀 문자를 접해본 적이 없다면 Fig.6의 타밀 문자 로고를 보고 글자라고 생각하기 어려울 수 있다. 반대로 한글을 접해본 적 없는 외국인이라면 한국어 로고를 보고 단순한 그림이라고 생각하기 쉽다. 하지만 우리는 처음보는 언어라 하더라도 Fig.7의 간판을 보고 높은 확률로 글자일 것이라 예측할 수 있다. {{< hl-text primary >}}글자가 존재해야 할 곳에 무엇가 존재한다면 <b>식별이 불가능하더라도</b> 마땅히 글자라고 예측할 수 있다.{{< /hl-text >}} 이와 같이 모집단과 유사한 데이터를 통해서만 학습할 수 있는 부분이 많다.  
하지만 유사하지 않은 데이터가 무조건 나쁘다고 할 수는 없다. 예를들어 풀고자 하는 문제가 어려우면 어려울수록 loss의 수렴을 위해 필요한 데이터의 최소량이 크다. 그로인해 유사성의 중요도가 상대적으로 낮아지는 경우가 있다.  
그리고 모집단과 유사하지 않더라도 다양한 데이터는 모델의 precision 향상에는 도움이 된다. 배운 적 없는 새로운 경험은 기존에 풀지 못하던 문제를 풀 수 있게 해주기도 하기 때문이다. 하지만 recall에는 악영향을 주기도 한다.   
우리는 Fig.5의 예시를 통해 모집단과 유사한 자연스러운 이미지의 중요성을 알 수 있다. 이상적으로는 다양성과 유사성 둘을 동시에 확보하는 것이 타당하다. 하지만 그건 생각보다 어렵기 때문에 trade-off에 대해 고민을 할 수 밖에 없다.

#### Experience
Environments (Dockerfile)
```dockerfile
FROM nvcr.io/nvidia/pytorch:21.12-py3

ENV LD_PRELOAD=/opt/conda/lib/libmkl_core.so:/opt/conda/lib/libmkl_sequential.so

RUN apt-get update && apt-get install -y libsm6 libxext6 libxrender-dev && rm -rf /var/lib/apt/lists/*

RUN pip install h5py pygame

RUN git clone -b python3 https://github.com/ankush-me/SynthText.git
```

#### Reference
[1] M. Jaderberg et al. [Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition](https://www.robots.ox.ac.uk/~vgg/publications/2014/Jaderberg14c)  
[2] A. Gupta et al. [Synthetic Data for Text Localisation in Natural Images](https://www.robots.ox.ac.uk/~vgg/publications/2016/Gupta16)  
[3] P. Perez et al. [Poisson Image Editing](https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf)  
[4] P. Arbelaez et al. [Contour Detection and Hierarchical Image Segmentation](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf)
